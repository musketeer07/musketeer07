


## Hi there ðŸ‘‹

<!--
**musketeer07/musketeer07** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
-->

### About Me

I am a data engineer and analyst with a strong passion for transforming data into actionable insights to drive business success. With a Bachelor's degree in Computer Science & Engineering and a Master's degree in Applied Computer Science from Concordia University, I have developed a comprehensive skill set in data engineering and analytics.

I am eager to apply my skills and experience to guide companies in leveraging data for strategic business decisions. Feel free to explore my projects and connect with me to discuss potential collaborations or share insights on the latest trends in data engineering and analytics.

### ðŸ”­ Iâ€™m currently working on
- Leading the development of a cloud data enablement project at Intact Financial Corporation, enhancing data ingestion processes to handle over 10 million records weekly.
- Streamlining large-scale migrations with automated Snowflake-based ETL pipelines.

### ðŸŒ± Iâ€™m currently learning
- Advanced data engineering techniques.
- Preparing for the Azure Data Engineering Associate certification.

### ðŸ‘¯ Iâ€™m looking to collaborate on
- Innovative data engineering and analytics projects.
- Building robust and scalable ETL pipelines.

### ðŸ¤” Iâ€™m looking for help with
- Exploring new and efficient ways to leverage big data technologies for business insights.

### ðŸ’¬ Ask me about
- Data engineering
- Cloud platforms
- Big data technologies
- Interactive dashboards

### ðŸ“« How to reach me
- Email: [vaibhavsehgaljobs@gmail.com](mailto:vaibhavsehgaljobs@gmail.com)
- LinkedIn: [Vaibhav Sehgal](https://www.linkedin.com/in/sehgalvaibhav)
- GitHub: [musketeer07](https://github.com/musketeer07)
- Portfolio: [vaibhavsehgal.info](http://www.vaibhavsehgal.info)

### ðŸ˜„ Pronouns
- He/Him

### âš¡ Fun fact
- I love creating movie recommendation systems and have built one using Numpy, Pandas, Scikit-learnâ€™s Tfidf Vectorizer, and collaborative algorithms like SVD/ALS for enhanced suggestion accuracy.

## Technical Skills

- **Programming Languages**: Python, Scala, Java, SQL, HTML, CSS, JavaScript
- **Databases**: MySQL, Microsoft SQL Server, NoSQL, PostgreSQL, MongoDB
- **Big Data Technologies**: Apache Spark, PySpark, Hadoop, Airflow, Hive, Kafka, Informatica
- **Developer Tools**: Power BI, Tableau, GitHub, JIRA, Confluence, Docker, Jenkins, Unix Shell, Linux
- **Cloud Platforms**: AWS (EC2, S3, EMR, Glue, QuickSight, Load Balancer), Azure, Snowflake, Databricks, Redshift
- **Certifications**: Snowflake Data Warehousing, BI DAX Modeling, Preparing Azure Data Engineering Associate

## Projects

### 1. 360 Degree View of Prescriber
- **Technologies Used**: Python, PySpark, SQL, AWS (Redshift, S3, Lambda)
- **Description**: Created PySpark scripts for extracting, cleaning, and transforming data from S3 to AWS Redshift. Developed complex SQL queries and set up lambda triggers for analytics, optimizing data flow for cost and time.

### 2. Movie Recommendation System
- **Technologies Used**: Python, Pandas, Scikit-Learn, Matplotlib, EDA, Surprise, Plotly
- **Description**: Developed a precise movie recommendation system using Numpy, Pandas, Scikit-learnâ€™s Tfidf Vectorizer, and collaborative algorithms like SVD/ALS for enhanced suggestion accuracy.
- **Repository**: [Movie Recommendation Engine](https://github.com/musketeer07/movie-recommendation-engine)

### 3. Cloud Data Enablement Project
- **Technologies Used**: Snowflake, AWS, SQL, Jenkins
- **Description**: Led the development of a project enhancing data ingestion processes, handling over 10 million records weekly. Created automated Snowflake-based ETL pipelines and improved query performance by 40%.

### 4. Interactive Power BI Dashboards
- **Technologies Used**: Power BI, AWS Glue, PySpark
- **Description**: Designed and deployed interactive dashboards for real-time data analysis and KPI calculation, providing actionable insights for decision-making and increasing reporting efficiency by 45%.
